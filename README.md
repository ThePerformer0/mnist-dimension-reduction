# ğŸ§  MNIST Dimension Reduction

Ce projet explore et compare trois techniques de **rÃ©duction de dimension** appliquÃ©es au cÃ©lÃ¨bre dataset **MNIST** (images de chiffres manuscrits). Lâ€™objectif est de transformer des donnÃ©es initialement en **784 dimensions** (28x28 pixels) vers **2 ou 3 dimensions** pour :
- Faciliter la **visualisation**,
- RÃ©duire la complexitÃ© des modÃ¨les,
- AmÃ©liorer certaines Ã©tapes de **clustering ou classification**.

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ce projet a Ã©tÃ© conÃ§u pour :
- Comprendre les **principes fondamentaux** de la rÃ©duction de dimension.
- Comparer les mÃ©thodes **linÃ©aires (PCA)** et **non-linÃ©aires (t-SNE, UMAP)**.
- Visualiser lâ€™impact des rÃ©ductions sur la sÃ©paration des classes.
- Analyser lâ€™utilitÃ© de ces techniques en **prÃ©traitement** avant clustering ou apprentissage supervisÃ©.

---

## ğŸ“Š Techniques Ã©tudiÃ©es

| MÃ©thode | Type | Avantages | Limites |
|--------|------|-----------|---------|
| **PCA** | LinÃ©aire | Simple, rapide, interprÃ©table | Ne capte pas les relations non linÃ©aires |
| **t-SNE** | Non-linÃ©aire | TrÃ¨s bon pour la visualisation locale | CoÃ»teux, pas gÃ©nÃ©ralisable |
| **UMAP** | Non-linÃ©aire | Rapide, prÃ©serve mieux la structure globale | ParamÃ©trage plus complexe |

---

## ğŸ§± Structure du projet

```

mnist-dimension-reduction/
â”‚
â”œâ”€â”€ README.md                   # Documentation du projet
â”œâ”€â”€ requirements.txt            # BibliothÃ¨ques Ã  installer
â”œâ”€â”€ .gitignore                  # Fichiers/dossiers Ã  ignorer par Git
â”‚
â”œâ”€â”€ data/                       # DonnÃ©es d'entrÃ©e (CSV MNIST)
â”‚   â””â”€â”€ mnist.csv
â”‚
â”œâ”€â”€ notebooks/                  # Notebooks Jupyter pour chaque mÃ©thode
â”‚   â”œâ”€â”€ 01\_pca\_mnist.ipynb
â”‚   â”œâ”€â”€ 02\_tsne\_mnist.ipynb
â”‚   â”œâ”€â”€ 03\_umap\_mnist.ipynb
â”‚   â””â”€â”€ 04\_comparaison.ipynb
â”‚
â””â”€â”€ visualisations/             # Graphiques et figures gÃ©nÃ©rÃ©s
â””â”€â”€ figures/

````

---

## âš™ï¸ Installation et exÃ©cution

```bash
# Cloner le repo
git clone https://github.com/ThePerformer0/mnist-dimension-reduction.git
cd mnist-dimension-reduction

# CrÃ©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
````

---

## ğŸ§ª Datasets

Nous utilisons le dataset MNIST au format CSV :

* Lien Kaggle : [MNIST CSV Format â€“ Aditya Kashyap](https://www.kaggle.com/datasets/adityaanilkashyap/the-mnist-dataset-in-csv-format)
* Contenu : 70â€¯000 Ã©chantillons (60k train + 10k test), avec labels inclus
* Format : chaque ligne contient un label (0 Ã  9) suivi des 784 pixels

---

## ğŸ“ˆ RÃ©sultats obtenus

### Comparaison visuelle des trois mÃ©thodes

Les figures ci-dessous montrent les projections 2D obtenues avec chaque mÃ©thode sur un Ã©chantillon du dataset MNIST :

![Projection UMAP](visualisations/figures/UMAP_2D_Visualization.png)

*Figure 1 : Projection 2D avec UMAP - SÃ©paration optimale des classes*

![Projection t-SNE](visualisations/figures/T-SNE_Visualization.png)

*Figure 2 : Projection 2D avec t-SNE - Bonne sÃ©paration locale*

![Projection PCA](visualisations/figures/projection-2D-via-PCA.png)

*Figure 3 : Projection 2D avec PCA - SÃ©paration limitÃ©e*

![Exemples MNIST](visualisations/figures/Image_number.png)

*Figure 4 : Exemples d'images pour chaque chiffre (0-9)*



| MÃ©thode | QualitÃ© de sÃ©paration | Structure prÃ©servÃ©e | Temps de calcul |
|---------|---------------------|-------------------|----------------|
| **UMAP** | â­â­â­â­â­ Excellente | Globale + Locale | Rapide |
| **t-SNE** | â­â­â­â­ TrÃ¨s bonne | Principalement locale | Lent |
| **PCA** | â­â­ LimitÃ©e | LinÃ©aire uniquement | TrÃ¨s rapide |

### Observations par mÃ©thode

#### ğŸ¯ UMAP - La plus performante
- **SÃ©paration optimale** : Chaque chiffre forme des clusters distincts et bien dÃ©finis
- **Structure prÃ©servÃ©e** : Maintient Ã  la fois les relations locales et globales
- **Chiffres parfaitement isolÃ©s** : 0, 1, 2, 4, 6, 9 forment des Ã®lots complÃ¨tement sÃ©parÃ©s
- **Zones de confusion minimales** : LÃ©ger chevauchement uniquement entre 3, 5, 8 (chiffres morphologiquement similaires)

#### ğŸ” t-SNE - Bonne visualisation locale
- **Clusters visibles** : SÃ©paration claire de la plupart des chiffres
- **Structure locale excellente** : PrÃ©serve bien les voisinages proches
- **Chevauchements plus nombreux** : Zones de mÃ©lange entre plusieurs classes
- **Disposition moins optimale** : Certains clusters proches peuvent crÃ©er de la confusion

#### ğŸ“Š PCA - MÃ©thode linÃ©aire limitÃ©e
- **SÃ©paration insuffisante** : Forte superposition de la majoritÃ© des classes
- **Structure circulaire** : Disposition en nuage sans clusters distincts
- **Seul le chiffre 1 se distingue** : LÃ©gÃ¨rement sÃ©parÃ© du nuage principal
- **InadÃ©quate pour MNIST** : Les relations non-linÃ©aires ne sont pas capturÃ©es

---

## ğŸ§  InterprÃ©tations & analyses

### Ce qu'on apprend sur la nature des donnÃ©es MNIST

1. **ComplexitÃ© non-linÃ©aire** : Les chiffres manuscrits prÃ©sentent des variations qui ne peuvent pas Ãªtre capturÃ©es par une transformation linÃ©aire simple (Ã©chec de PCA).

2. **Structure intrinsÃ¨que** : MalgrÃ© la haute dimensionnalitÃ© (784 dimensions), les donnÃ©es possÃ¨dent une structure sous-jacente de dimension bien plus faible, rÃ©vÃ©lÃ©e par UMAP et t-SNE.

3. **SimilaritÃ©s morphologiques** : Les confusions observÃ©es (3/5/8, 4/9, 6/8) reflÃ¨tent les similaritÃ©s visuelles rÃ©elles entre ces chiffres dans l'Ã©criture manuscrite.

### UtilitÃ© en prÃ©traitement

#### Pour le clustering non-supervisÃ©
- **UMAP recommandÃ©** : PrÃ©servation optimale de la structure pour des algorithmes comme K-means
- **t-SNE acceptable** : Mais risque de sur-optimisation pour la visualisation
- **PCA dÃ©conseillÃ©** : Perte d'information critique

#### Pour la classification supervisÃ©e
- **UMAP** : Excellent prÃ©traitement, rÃ©duction significative de la dimensionnalitÃ© sans perte de sÃ©parabilitÃ©
- **PCA** : Peut Ãªtre utilisÃ© pour une rÃ©duction rapide en premiÃ¨re Ã©tape, mais insuffisant seul
- **t-SNE** : Non recommandÃ© (pas de transformation out-of-sample)

### Cas d'usage optimaux par mÃ©thode

#### Choisir UMAP quand :
- On souhaite la **meilleure sÃ©paration possible**
- Il faut prÃ©server Ã  la fois la **structure locale et globale**
- Le dataset est de **taille moyenne Ã  grande**
- On veut un **prÃ©traitement performant** pour du clustering/classification

#### Choisir t-SNE quand :
- L'objectif principal est la **visualisation exploratoire**
- On s'intÃ©resse aux **relations de proximitÃ© locale**
- Le dataset est de **taille modÃ©rÃ©e**
- Le temps de calcul n'est **pas critique**

#### Choisir PCA quand :
- On a besoin d'une **rÃ©duction rapide**
- L'**interprÃ©tabilitÃ©** des composantes est importante
- Il faut une mÃ©thode **dÃ©terministe et reproductible**
- C'est une **premiÃ¨re Ã©tape** avant d'autres techniques

---

## ğŸ”— Ressources utiles

* [scikit-learn â€“ PCA & t-SNE](https://scikit-learn.org/stable/modules/manifold.html)
* [UMAP-learn Documentation](https://umap-learn.readthedocs.io/en/latest/)
* [MNIST Dataset Info â€“ Yann LeCun](http://yann.lecun.com/exdb/mnist/)

---

## ğŸ¤ Contribution

Toute contribution (amÃ©lioration du code, meilleure visualisation, benchmark additionnelâ€¦) est la bienvenue !
Pour contribuer :

1. Fork le projet
2. CrÃ©e une branche
3. Propose un Pull Request

---

## ğŸ§‘â€ğŸ’» Auteur

Projet rÃ©alisÃ© par [The Performer](https://github.com/ThePerformer0) dans un but Ã©ducatif et de partage.
